# Curriculum

* [Introduction to astrophotography](#introduction-to-astrophotography)
* [Image acquisition](#image-acquisition)
* [Image calibration](#image-calibration)
* [Image stacking](#image-stacking)
* [Image enhancement](#image-enhancement)
* [Color processing](#color-processing)
* [Advanced techniques](#advanced-techniques)
* [Image analysis](#image-analysis)

# Introduction to astrophotography

Learn the basics of astrophotography, including the equipment used, camera settings, and exposure times.

# Image acquisition

Learn how to capture images of the night sky using a digital camera or a telescope.

# Image calibration

Learn how to process raw astronomical images, including dark frame subtraction, flat field correction, and bias
correction.

## 1. Introduction to image calibration

Calibration - also known as "reduction" - is a process which removes various defects from images. It ensures the capabilities of the imaging system are maximized.

Sources of defects:

* Readout noise - generated by electronics in sensor including pixel and amplifiers
* Thermal noise - heat from ambient environment and generated by electronics during exposure 
* Optical defects - vignetting or defects optical elements, dust, filters
* Environmental effects - sky glow and seeing
* Shot noise - inherent result of physical phenomena involving quantized packets (e.g. photos and electrons)

Thermal noise can be dramatically reduced by cooling the sensor.

Shot noise cannot be removed via calibration, so imaging requires long exposures to increase signal above the noise floor.

Some pixels will be more sensitive than others ("hot"); however, because the source of this noise involves discrete quantized packets, calibration cannot completely remove noise from these pixels.

The amount of noise varies between sources. For example, among all hot pixels, some will be hotter than others. Also, the relation between noise and temperature may be non-linear.

<dl>
   <dt>Bias frames</dt>
   <dd>Used to capture electronic bias inherent in sensor (zero point), so it can be removed from light frames. Does not capture or account for read noise.</dd>

   <dt>Dark frames</dt>
   <dd>Used to capture noise caused by heat generated during exposures and amplifiers (dark current), so it can be removed from light frames. Includes electronic bias, so bias frames must be subtracted from dark frames, or only dark frames should be used (no bias frames) - <em>❓ is this true❓</em></dd>

   <dt>Flat frames</dt>
   <dd>Used to capture optical imperfections in imaging path, so it can be corrected for. Can correct for minor vignette, sensor mottling (if any), as well as dust and other stray particles. Captured when all pixels are irradiated the same amount. During image processing, light frames are divided by flat frames. This effectively normalizes the range of each pixel by reducing the brightness of pixels with few optical obstructions.</dd>

   <dt>Flat dark frames</dt>
   <dd>Alternative to bias and dark frames for sensors that can't capture these types of calibration frames effectively.</dd>
</dl>

Reference:

* https://cdn.diffractionlimited.com/help/maximdl/MaxIm-DL.htm#Calibration.htm
* https://telescope.live/blog/learning-about-amp-glow#:~:text=Amplifier%20glow%20refers%20to%20a,circuitry%20of%20the%20imaging%20chip.

## 2. Dark frame subtraction

Dark bias correction (includes sensor bias):

```python
dark_corrected_image = raw_image - reference_dark_image
```

Reference:

* https://prancer.physics.louisville.edu/astrowiki/index.php/Image_processing_with_Python_and_SciPy#Correcting_and_Combining_Images


## 3. Flat field correction

Flat field correction can be performed two ways:

1. Using normalized flat-field image: dividing each pixel from flat frame into the average value in the array of pixels, then multiplying the light frame by the result. (?) Should this be done for each flat frame, then average the resulting set of frames?
2. Dividing light frame by flat frame: averaging flat frames, then dividing the light frame by the result

```python
final_image = dark_corrected_image / reference_flat_image
```

Reference:

* https://www.macobservatory.com/blog/2018/11/3/how-to-take-easy-flats-using-an-inexpensive-light-source
* https://prancer.physics.louisville.edu/astrowiki/index.php/Image_processing_with_Python_and_SciPy#Correcting_and_Combining_Images
* https://homepages.inf.ed.ac.uk/rbf/HIPR2/pixdiv.htm

## 4. Bias correction

This isn't necessary when using dark frames, because dark frames include electronic bias; however, if bias frames were used, the correction would use subtraction.

## 5. Advanced techniques

Master frames and frame library: to save time, a library of calibration frames can be created ahead of time. This avoids the time-consuming process of creating calibration frames during an imaging session. Most (all?) calibration frames can be created while the sun is up; however, accounting for temperature is only possible with actively cooled sensors. Scaling (below) can be used to calibrate light frames when an exact match isn't availble in the master library.

Scaling: scaling values of a dark frame based on temperature or exposure. This can create dark frames when they don't exist for a specific temperature or exposure. If using this technique, bias frames should be used. Same is true if using flat frames and _not_ dark frames (flat-darks).

Kernel filtering and dithering: hot pixels cannot be completely removed via calibration. As a solution, these pixels can be replaced using values from surrounding pixels (kernel filtering). A better alternative is to "dither" during imaging - point the camera between light images. This distributes hot pixels across multiple images, so the effect is averaged out during stacking.

Sky-/twilight-flats: using from the sky to create flat frames. Dithering should be used if no diffuse filter.

## 6. In practice

Order of operations: division and subtraction are not [commutative](https://en.wikipedia.org/wiki/Commutative_property), so these calibration operations must be done in a specific order.

Bias frame not required: bias can be removed using a bias frame or by ensuring bias is subtracted as a result of other operations: subtract a dark from the light frame, and subtract a flat-dark from the flat-field. [Details](https://cdn.diffractionlimited.com/help/maximdl/MaxIm-DL.htm#Calibration.htm).

Calibrating a light frame by subtracting a single dark frame actually _introduces_ noise, because read noise and residual dark current noise vary over time. For this reason, multiple dark frames should be averaged. Every time you quadruple the number of averaged frames, you drop the noise contribution in half.

Dark and flat frames should be captured using same exposure as light frames. Dust can accumulate on the sensor during imaging, and jostling the instrument can dislodge dist. For these reasons, flat frames should be taken immediately after capturing light frames. Bias frames - if used - should be taken with minimal exposure.

Exposure time of flat frames should result in values near the middle of the possible range of values. This avoids non-linearity in noise at bottom and top of the range.

To ensure calibration is effective, compare similar calibration frames to ensure the behavior of noise sources are what's expected. For example, take a dark frame and compare to a dark frame from previous imaging session.

Sensor bias is mostly stable over time, so bias frames could be used for multiple imaging sessions (possibly months).

## 8. Outstanding questions
* How should frames be combined? Which frames need bias removal? When to subtract vs divide? Does order matter?
* What are flat-dark frames?
* If creating a calibration frame library, how do you account for temperature?
* How many calibration frames should be included in a master frame?
* Are sky / twilight frames possible?

# Image stacking

Learn how to combine multiple images to increase the signal-to-noise ratio and produce a final image
with greater detail.

### 1. Introduction to image stacking: Learn the basics of image stacking and its importance in astrophotography.
### 2. Image acquisition: Learn how to capture images of the night sky using a digital camera or a telescope.
### 3. Image calibration: Learn how to process raw astronomical images, including dark frame subtraction, flat field correction, and bias correction.
### 4. Registration: Learn how to align and register multiple images to be stacked, including techniques for eliminating field rotation, field curvature, and focal plane distortion.
### 5. Methods: Learn about different image stacking methods, including average stacking, median stacking, and sigma clipping.
### 6. Settings: Learn how to adjust image stacking settings to produce the best final image, including choosing the right number of images to stack and the best stacking method.
### 7. Post-processing: Learn how to post-process the final stacked image using techniques such as histogram stretching, noise reduction, and sharpening.

Stretching is a method for increasing contrast to work around physical limitations of displays. Displays cannot produce the contrast inherent in the image, but the image itself can be adjusted to work around this problem.

Stretching can be applied only when viewing an image, or it can be baked-in to an image.

Stretching methods:

* Log rescale: applying log function to values
* [Gamma correction](https://en.wikipedia.org/wiki/Gamma_correction): scaling values using exponentiation. Affects mid values the most. Gamma < 1 increases brightness, while Gamma > 1 decreases brightness.
* Curves: manually defining how values are adjusted by manipulating the curves of mapping function. Can be applied uniformly to all color channels, or separately to each channel.
* Histogram fitting: manipulating the histogram of values. Values are adjusted to fit the manipulated histogram.

# Image enhancement

Learn how to process and enhance final images using techniques such as histogram stretching, noise
reduction, and sharpening.

1. Introduction to image enhancement: Learn the importance of image enhancement in astrophotography and its impact
   on the final image quality.
2. Image processing software: Learn how to use image processing software, such as Adobe Photoshop, GIMP, or
   PixInsight, to enhance astrophotographic images.
2. Histogram stretching: Learn how to adjust the image brightness and contrast using histogram stretching to bring
   out faint details in the image.
2. Noise reduction: Learn how to reduce the noise in an image using techniques such as wavelet processing, selective
   smoothing, and median filtering.
2. Sharpening: Learn how to sharpen the details in an image using techniques such as unsharp masking, high-pass
   filtering, and deconvolution.
2. Color processing: Learn how to adjust the colors in an image to bring out the best representation of the night
   sky, including techniques for color balancing, color correction, and color grading.
2. Layer masks: Learn how to use layer masks to selectively apply image processing techniques to specific areas of
   an image.

# Color processing

Learn how to create a color image from a set of monochrome images captured through different
filters.

1. Introduction to color processing: Learn the importance of color processing in astrophotography and its impact on the
   final image quality.
1. Color theory: Learn the basics of color theory and how it applies to astrophotography.
1. Image processing software: Learn how to use image processing software, such as Adobe Photoshop, GIMP, or PixInsight,
   to process the colors in astrophotographic images.
1. Color balancing: Learn how to balance the colors in an image to achieve a natural-looking representation of the night
   sky.
1. Color correction: Learn how to correct the colors in an image to bring out the best representation of the celestial
   objects, including techniques for removing color casts, fixing white balance, and adjusting saturation.
1. Color grading: Learn how to adjust the colors in an image for artistic effect, including techniques for color grading
   and creating color-lookup tables.
1. Layer masks: Learn how to use layer masks to selectively apply color processing techniques to specific areas of an
   image.

# Advanced techniques

Learn about advanced techniques such as luminance layering, layer masks, and star tracking for
capturing sharp images of the night sky.

1. Advanced image processing techniques: Learn about advanced image processing techniques, including non-linear image
   processing, HDR imaging, and advanced color processing.
1. Advanced stacking techniques: Learn about advanced stacking techniques, including median stacking, sigma clipping,
   and multiscale processing.
1. Image restoration: Learn about techniques for restoring images, including removing artifacts, correcting distortion,
   and repairing damage.
1. Astrophotography with telescopes: Learn how to capture astrophotographic images using a telescope, including
   techniques for focusing, guiding, and stacking.
1. Astrophotography with specialized cameras: Learn how to capture astrophotographic images using specialized cameras,
   such as CCD or CMOS cameras.
1. Astrophotography with narrowband filters: Learn how to capture images using narrowband filters, including
   hydrogen-alpha, oxygen-iii, and sulfur-ii filters.
1. Image integration: Learn how to integrate multiple images captured under different conditions or with different
   equipment to produce a final image with improved quality and detail.

# Image analysis

Learn how to analyze astrophotographic images to extract scientific information, such as determining
the position and brightness of stars, the size of galaxies, and the presence of nebulae.

1. Introduction to image analysis: Learn about the importance of image analysis in astrophotography and its role in
   extracting scientific information from images.
1. Image processing software: Learn how to use image processing software, such as PixInsight or IRAF, for image
   analysis.
1. Photometry: Learn how to measure the brightness of celestial objects in an image, including techniques for aperture
   photometry, PSF photometry, and profile fitting.
1. Astrometry: Learn how to measure the positions of celestial objects in an image, including techniques for plate
   solving and world coordinate systems.
1. Image statistics: Learn how to extract information about the distribution and properties of the data in an image,
   including techniques for computing mean, median, mode, standard deviation, and skewness.
1. Image visualization: Learn how to visualize the data in an image, including techniques for creating histograms,
   contour plots, and surface plots.
1. Object detection: Learn how to detect celestial objects in an image, including techniques for source extraction,
   deblending, and false detection removal.